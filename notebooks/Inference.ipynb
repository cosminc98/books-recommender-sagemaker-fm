{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Book Recommendation Inference\n",
    "---\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "    * [Background](#Introduction-Background)\n",
    "    * [Definitions](#Introduction-Definitions)\n",
    "    * [Prerequisites](#Introduction-Prerequisites)\n",
    "2. [Notebook Setup](#Notebook-Setup)\n",
    "3. [Code](#Code)\n",
    "    * [Imports](#Code-Imports)\n",
    "    * [File Paths](#Code-File-Paths)\n",
    "    * [Load Input Files](#Code-Load-Input-Files)\n",
    "    * [Deploy the Endpoint](#Code-Deploy-the-Endpoint)\n",
    "    * [Create Predictor from Endpoint Name](#Code-Create-Predictor-from-Endpoint-Name)\n",
    "    * [Inference Functions](#Code-Inference-Functions)\n",
    "    * [Display Functions](#Code-Display-Functions)\n",
    "    * [Example Recommendations](#Code-Example-Recommendations)\n",
    "    * [Cleanup](#Code-Cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Introduction\"></a>\n",
    "## Introduction\n",
    "---\n",
    "<a id=\"Introduction-Background\"></a>\n",
    "### Background\n",
    "In our application we'll have anonymous users provide a few books that they liked and we need to give them book recommendations based on those. Our factorization machine model provides a way to score books given the user context (the books that the user said they liked). However, there are almost 200k to search from, which would be computationally expensive to score them all and may introduce noise from wrong predictions. We reduce the search space using the proximal books obtained from the \"BooksRecommenderProximity\" notebook. This notebook provides the inference method to score the proximal books and provide anonymous users with book recommendations.\n",
    "\n",
    "<a id=\"Introduction-Definitions\"></a>\n",
    "### Definitions\n",
    "| Term | Definition |\n",
    "|:--- |:--- | \n",
    "| Context Book | A book that is provided by the user, with the assumption that they liked it (explicit feedback), that will be used to rank recommendations using the factorization machine model. The context books are only a subset of the book dataset since some books did not have enough data during training. **Users may only choose liked books from this subset.** |\n",
    "| Target Book | A book that can be scored by the factorization machine model. The target books are only a subset of the book dataset since some books did not have enough data during training. **Users will receive recommendations only from this subset.** |\n",
    "| Encoder | The encoders we refer to in this notebook are either **sklearn.preprocessing.OneHotEncoder** for the target books (since we only have one per prediction), or **sklearn.preprocessing.MultiLabelBinarizer** for the context books (since we have multiple ones for each prediction). **We load these encoders to retrieve the context and target book subsets.** |\n",
    "| Proximal Book | A context book has multiple proximal books that are \"close\" to it. Here, \"close\" means that users that liked the context book also liked the proximal books. Books from the same authors are also considered proximal. |\n",
    "| ISBN | International Standard Book Numbers (or ISBN) is a unique identified for each book. In particular, it is an identified for each specific version/revision of a given book, which is why we need to perform ISBN deduplication to map old versions to the latest one. We do this to treat all versions of the same book in as one single book. |\n",
    "\n",
    "<a id=\"Introduction-Prerequisites\"></a>\n",
    "### Prerequisites\n",
    "The following files are required, all of which are the result of training the model using the training notebook:\n",
    "- target_encoder.pkl\n",
    "    * Obtained from \"BooksRecommenderTraining\" notebook.\n",
    "    * Contains a python pickled object: The target ISBN one-hot encoder.\n",
    "- context_encoder.pkl\n",
    "    * Obtained from \"BooksRecommenderTraining\" notebook.\n",
    "    * Contains a python pickled object: The context ISBN multi-hot encoder.\n",
    "- same_book_isbn_map.json\n",
    "    * Obtained from \"BooksRecommenderTraining\" notebook.\n",
    "    * Contains a map from duplicate ISBNs to the latest ISBN that removes some duplicate books (different editions of the same book).\n",
    "- model.tar.gz\n",
    "    * Obtained from \"BooksRecommenderTraining\" notebook.\n",
    "    * Is an object stored on an s3 bucket (you need to know the path to the object) containing the factorization machine model parameters that are used to score proximal books so they can be ranked.\n",
    "- isbn_to_proximal_isbns.json\n",
    "    * Obtained from \"BooksRecommenderProximity\" notebook.\n",
    "    * Contains a map from context ISBNs to lists of proximal books (books that are similar).\n",
    "- books.csv\n",
    "    * Download [here](https://cosminc98-public-datasets.s3.eu-central-1.amazonaws.com/books-recommender/books.csv). Originally from [this](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset/) kaggle competition. If no longer available, download the original file [here](https://cosminc98-public-datasets.s3.eu-central-1.amazonaws.com/books-recommender/original/Books.csv), although this is not the one we use.\n",
    "    * Contains all metadata of the books in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Notebook-Setup'></a>\n",
    "## Notebook Setup\n",
    "---\n",
    "This notebook was tested in Amazon SageMaker Studio on a ml.t3.medium instance with Python 3 (Data Science) kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Code'></a>\n",
    "## Code\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='Code-Imports'></a>\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Set, Optional, Iterable\n",
    "from scipy.sparse import diags, hstack, csr_matrix\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.deserializers import JSONDeserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Code-File-Paths\"></a>\n",
    "### File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"books-recommender/anonymous-regressor\"\n",
    "training_output_prefix = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "# WARNING: You need to update this; look into your sagemaker s3 bucket to find \n",
    "# the model you trained\n",
    "model_path = f\"{training_output_prefix}/factorization-machines-2023-12-09-10-08-08-204/output/model.tar.gz\" \n",
    "\n",
    "model_dir = \"./\"\n",
    "same_book_isbn_fpath = os.path.join(model_dir, \"same_book_isbn_map.json\")\n",
    "target_encoder_fpath = os.path.join(model_dir, \"target_encoder.pkl\")\n",
    "context_encoder_fpath = os.path.join(model_dir, \"context_encoder.pkl\")\n",
    "proximity_map_fpath = os.path.join(model_dir, \"isbn_to_proximal_isbns.json\")\n",
    "\n",
    "data_dir = \"../../../data\"\n",
    "books_fpath = os.path.join(data_dir, \"books\", \"books.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Code-Load-Input-Files\"></a>\n",
    "### Load Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 149623 target books\n"
     ]
    }
   ],
   "source": [
    "with open(target_encoder_fpath, \"rb\") as f:\n",
    "    target_encoder = pickle.load(f)\n",
    "target_isbns = set(target_encoder.categories_[0])\n",
    "print(f\"There are {len(target_isbns)} target books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 170978 context books\n"
     ]
    }
   ],
   "source": [
    "with open(context_encoder_fpath, \"rb\") as f:\n",
    "    context_encoder = pickle.load(f)\n",
    "context_isbns = set(context_encoder.classes_)\n",
    "print(f\"There are {len(context_isbns)} context books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24636 duplicate ISBNs (different versions of the same book) that need to be mapped to the latest version of that book (ISBN)\n"
     ]
    }
   ],
   "source": [
    "with open(same_book_isbn_fpath, \"r\") as f:\n",
    "    same_book_isbn_map = json.load(f)\n",
    "print(f\"There are {len(same_book_isbn_map)} duplicate ISBNs (different versions of the same book) that need to be mapped to the latest version of that book (ISBN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 170978 books for which we have 100 similar books each (should be the same as the number of context books)\n"
     ]
    }
   ],
   "source": [
    "with open(proximity_map_fpath, \"r\") as f:\n",
    "    isbn_to_proximal_isbns = json.load(f)\n",
    "print(f\"There are {len(isbn_to_proximal_isbns)} books for which we have 100 similar books each (should be the same as the number of context books)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 131925 unique proximal books (ideally should be close or equal to the number of target books, but may be lower because some books are just too isolated, i.e. rated by only one person)\n"
     ]
    }
   ],
   "source": [
    "proximal_set: Set[str] = set()\n",
    "for proximal_isbns in isbn_to_proximal_isbns.values():\n",
    "    proximal_set.update(proximal_isbns)\n",
    "print(f\"There are {len(proximal_set)} unique proximal books (ideally should be close or equal to the number of target books, but may be lower because some books are just too isolated, i.e. rated by only one person)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "books_df = pd.read_csv(books_fpath, dtype={\n",
    "    \"ISBN\": str, \n",
    "    \"BookTitle\": str, \n",
    "    \"BookAuthor\": str, \n",
    "    \"YearOfPublication\": int, \n",
    "    \"Publisher\": str, \n",
    "    \"ImageURLSmall\": str, \n",
    "    \"ImageURLMedium\": str, \n",
    "    \"ImageURLLarge\": str\n",
    "})\n",
    "isbns = books_df.ISBN.tolist()\n",
    "authors = [auth.lower() for auth in books_df.BookAuthor]\n",
    "book_to_author: Dict[str, str] = dict(zip(isbns, authors))\n",
    "book_to_title: Dict[str, str] = dict(zip(isbns, books_df.BookTitle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Code-Deploy-the-Endpoint\"></a>\n",
    "### Deploy the Endpoint\n",
    "\n",
    "Do not forget to call this function if you're done with the endpoint as it will cost you a lot of money:\n",
    "```python\n",
    "fm_predictor.delete_endpoint()\n",
    "```\n",
    "\n",
    "Optionally, you may go to your AWS Console (in the SageMaker service) and delete the endpoint from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "--------------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Endpoint's name: factorization-machines-2023-12-09-12-10-55-722\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 20.6 ms, total: 256 ms\n",
      "Wall time: 10min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fm = sagemaker.FactorizationMachinesModel(\n",
    "    model_data=model_path,\n",
    "    role=get_execution_role(),\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "fm_predictor = fm.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.t2.medium\", # \"ml.c7g.xlarge\", # \"ml.c4.xlarge\",\n",
    "    deserializer=JSONDeserializer()\n",
    ")\n",
    "endpoint_name = fm_predictor.endpoint_name\n",
    "display(f\"Endpoint's name: {endpoint_name}\")\n",
    "\n",
    "# you can't use the fm_predictor from deployment in a lambda function because\n",
    "# you only deploy once; you have to use the endpoint name to initialize a\n",
    "# Predictor object; we therefore make this object \"None\" to show that you\n",
    "# cannot use it in practice\n",
    "fm_predictor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Code-Create-Predictor-from-Endpoint-Name\"></a>\n",
    "### Create Predictor from Endpoint Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# this is how a lambda function would initialize the predictor (by using its\n",
    "# name, not by deploying it again)\n",
    "fm_predictor = sagemaker.predictor.Predictor(\n",
    "    endpoint_name, \n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    deserializer=JSONDeserializer()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Code-Inference-Functions\"></a>\n",
    "### Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_if_duplicate(isbn: str, same_book_isbn_map: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Map current ISBN to the latest version if it is a duplicate.\n",
    "    \n",
    "    Args:\n",
    "        isbn: The ISBN to be mapped if it is a duplicate.\n",
    "        same_book_isbn_map: A map from duplicate ISBN's (old version of a book)\n",
    "            to the latest ISBN (the latest version of that book).\n",
    "            \n",
    "    Returns:\n",
    "        The ISBN after being mapped or not.\n",
    "    \"\"\"\n",
    "    if isbn in same_book_isbn_map:\n",
    "        return same_book_isbn_map[isbn]\n",
    "    return isbn\n",
    "\n",
    "\n",
    "def serialize(inputs_encoded: csr_matrix, float_decimals: Optional[int] = 5) -> str:\n",
    "    \"\"\"\n",
    "    Serialize the input data in json format according to\n",
    "    https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html#ir-serialization\n",
    "    before sending it to the factorization machine endpoint for inference.\n",
    "    \n",
    "    Args:\n",
    "        inputs_encoded (scipy.sparse.csr_matrix): A sparse matrix containing the \n",
    "            inference samples. Each sample (row) contains the user index and\n",
    "            the movie index so that the model may compute if the movie is good\n",
    "            for that specific user.\n",
    "        float_decimals: The floating point precision (number of decimals)\n",
    "            in the serialized json string. Used to reduce the size of the \n",
    "            output string. If None, rounding is not performed.\n",
    "            \n",
    "    Returns:\n",
    "        The serialized input in the json format.\n",
    "    \"\"\"\n",
    "    instances = []\n",
    "    shape = inputs_encoded.shape[1]\n",
    "    \n",
    "    for row in inputs_encoded:\n",
    "        values = [float(x) for x in row.data]\n",
    "        if float_decimals is not None:\n",
    "            values = [round(x, float_decimals) for x in values]\n",
    "            \n",
    "        instances.append({\n",
    "            \"data\": {\n",
    "                \"features\": {\n",
    "                    \"keys\": row.indices.tolist(), \n",
    "                    \"shape\": [shape], \n",
    "                    \"values\": values\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "            \n",
    "    return json.dumps({\n",
    "        \"instances\": instances\n",
    "    })\n",
    "\n",
    "\n",
    "def predict_scores(\n",
    "    target_ids: List[str],\n",
    "    context_ids: List[List[str]],\n",
    "    fm_predictor: sagemaker.predictor.Predictor,\n",
    ") -> List[float]:\n",
    "    \"\"\"\n",
    "    Use the factorization machine endpoint to predict scores for the pairs\n",
    "    of target book and context books.\n",
    "    \n",
    "    Args:\n",
    "        target_ids: A list of target books for which we are predicting a\n",
    "            suitability score.\n",
    "        context_ids: A list of lists of context books, which are used\n",
    "            to predict the score of the target.\n",
    "        fm_predictor: A predictor object that connects to the sagemaker\n",
    "            factorization machine endpoint.\n",
    "            \n",
    "    Returns:\n",
    "        A list of suitability scores that will be used for ranking books.\n",
    "    \"\"\"\n",
    "    # one-hot encode the target id\n",
    "    target_ids_encoded = target_encoder.transform(np.array(target_ids).reshape(-1, 1)).astype(\"float32\")\n",
    "    \n",
    "    # multi-hot encode the context ids\n",
    "    context_ids_encoded = context_encoder.transform(context_ids)\n",
    "    # normalize the multi-hot encoded vectors so that each sums up to 1; can \n",
    "    # handle context_ids of different lengths per target_id\n",
    "    context_ids_encoded = (diags([1 / len(x) for x in context_ids]) * context_ids_encoded).astype(\"float32\")\n",
    "    \n",
    "    # concatenate the target ids and the context ids along the column dimension\n",
    "    inputs_encoded = hstack([target_ids_encoded, context_ids_encoded], format=\"csr\")\n",
    "    \n",
    "    # serialize the sparse input matrix to json\n",
    "    inputs_json = serialize(inputs_encoded)\n",
    "    \n",
    "    # send the serialized inputs to the factorization machine endpoint\n",
    "    result = fm_predictor.predict(inputs_json, initial_args={\"ContentType\": \"application/json\"})\n",
    "    scores = [x[\"score\"] for x in result[\"predictions\"]]\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def recommend(\n",
    "    context_books: List[str], \n",
    "    same_book_isbn_map: Dict[str, str],\n",
    "    isbn_to_proximal_isbns: Dict[str, List[str]],\n",
    "    use_positional_bias: bool = True,\n",
    "    bias_strength: float = 0.5,\n",
    ") -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Recommends books based on a few (1-10 recommended) context books (which the\n",
    "    anonymous user has already read and liked). It does this by scoring the \n",
    "    proximal books of each context book and ranking them based on the score\n",
    "    and the positional bias (how close to the beginning of the proximal book\n",
    "    list a given book was; the closer it is to the front, the more likely it\n",
    "    is to be relevant).\n",
    "    \n",
    "    Args:\n",
    "        context_books: List of books that the user liked.\n",
    "        same_book_isbn_map: A map from duplicate ISBN's (old version of a book)\n",
    "            to the latest ISBN (the latest version of that book).\n",
    "        isbn_to_proximal_isbns: A map from context ISBNs to lists of proximal \n",
    "            books.\n",
    "        use_positional_bias: If True, will bias the scores towards proximal \n",
    "            books that are close to the beginning of their respective list.\n",
    "            The effect of this is reducing noise coming from irrelevant books\n",
    "            at the end of the list for which the factorization machine model\n",
    "            accidentally provides a large score.\n",
    "        bias_strength: A coefficient describing the positional bias influence.\n",
    "        \n",
    "    Returns:\n",
    "        A list of book recommendations (tuple of ISBNs and scores) sorted by\n",
    "        the suitability score in decreasing order.\n",
    "    \"\"\"\n",
    "    context_books = [\n",
    "        map_if_duplicate(isbn, same_book_isbn_map) for isbn in context_books\n",
    "    ]\n",
    "    \n",
    "    for isbn in context_books:\n",
    "        if isbn not in context_isbns:\n",
    "            raise ValueError(f'Book with ISBN \"{isbn}\" not in the context subset.')\n",
    "            \n",
    "    position_bias = None\n",
    "    if use_positional_bias:\n",
    "        position_bias: List[float] = []\n",
    "        \n",
    "    target_ids: List[str] = []\n",
    "    for context_id in context_books:\n",
    "        # get proximal books of context books; we score only those books (at \n",
    "        # most 100 per context book) as a way of reducing the search space\n",
    "        # since there are hundreds of thousands of books in the dataset\n",
    "        proximal_isbns = isbn_to_proximal_isbns[context_id]\n",
    "        \n",
    "        # filter out proximal books that are given as context\n",
    "        proximal_isbns = list(\n",
    "            filter(lambda isbn: isbn not in set(context_books), proximal_isbns)\n",
    "        )\n",
    "        # filter out proximal books that were added by another context book\n",
    "        proximal_isbns = list(\n",
    "            filter(lambda isbn: isbn not in set(target_ids), proximal_isbns)\n",
    "        )\n",
    "        \n",
    "        if len(proximal_isbns) > 0:\n",
    "            target_ids.extend(proximal_isbns)\n",
    "            if position_bias is not None:\n",
    "                position_bias.extend([\n",
    "                    1 - idx/len(proximal_isbns) \n",
    "                    for idx in range(len(proximal_isbns))\n",
    "                ])\n",
    "    \n",
    "    # for each target isbn (book that we want to score) we will provide the\n",
    "    # same context (what books the user liked, which will be used to score\n",
    "    # the targets)\n",
    "    context_ids: List[List[str]] = list(\n",
    "        itertools.repeat(context_books, times=len(target_ids))\n",
    "    )\n",
    "    \n",
    "    scores = predict_scores(target_ids, context_ids, fm_predictor)\n",
    "    if position_bias is not None:\n",
    "        scores = [score + bias_strength * bias for score, bias in zip(scores, position_bias)]\n",
    "        \n",
    "    scored_books: List[Tuple[str, float]] = list(\n",
    "        sorted(\n",
    "            zip(target_ids, scores), \n",
    "            key=lambda x: x[1],\n",
    "            reverse=True, \n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return scored_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Code-Display-Functions\"></a>\n",
    "### Display Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_book(title: str, author: str, score: Optional[float] = None) -> None:\n",
    "    if len(title) > 40:\n",
    "        title = title[:37] + \"...\"\n",
    "    if len(author) >= 40:\n",
    "        author = author[:37] + \"...\"\n",
    "    output = f'\"{title}\" by \"{author}\"'\n",
    "    if score is not None:\n",
    "        output = f\"[{score:.3f}] \" + output\n",
    "    print(output)\n",
    "\n",
    "\n",
    "def display_recommendations(\n",
    "    scored_books: List[Tuple[str, float]],\n",
    "    context_books: List[str],\n",
    "    book_to_author: Dict[str, str], \n",
    "    book_to_title: Dict[str, str],\n",
    "    best_n_only: Optional[int] = 20,\n",
    ") -> None:\n",
    "    n = len(scored_books)\n",
    "    if best_n_only:\n",
    "        n = min(n, 20)\n",
    "        \n",
    "    print(\"The books that the recommendations were based on:\")\n",
    "    for isbn in context_books:\n",
    "        title = book_to_title[isbn]\n",
    "        author = book_to_author[isbn]\n",
    "        print_book(title, author)\n",
    "          \n",
    "    print(\"\\nThe recommended books:\")\n",
    "    for isbn, score in scored_books[:n]:\n",
    "        title = book_to_title[isbn]\n",
    "        author = book_to_author[isbn]\n",
    "        print_book(title, author, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Code-Example-Recommendations\"></a>\n",
    "### Example Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The books that the recommendations were based on:\n",
      "\"The Selfish Gene\" by \"richard dawkins\"\n",
      "\"Climbing Mount Improbable\" by \"richard dawkins\"\n",
      "\"A Clash of Kings (A Song of Ice and F...\" by \"george r.r. martin\"\n",
      "\n",
      "The recommended books:\n",
      "[1.189] \"A Clash of Kings (A Song of Fire and ...\" by \"george r. r. martin\"\n",
      "[1.162] \"Windhaven\" by \"george r. r. martin\"\n",
      "[1.150] \"Warchild\" by \"karin lowachee\"\n",
      "[1.143] \"A Storm of Swords (A Song of Ice and ...\" by \"george r.r. martin\"\n",
      "[1.118] \"The Blind Watchmaker: Why the Evidenc...\" by \"richard dawkins\"\n",
      "[1.110] \"The Biotech Century: Harnessing the G...\" by \"jeremy rifkin\"\n",
      "[1.106] \"Shock\" by \"robin cook\"\n",
      "[1.097] \"Battlefield Earth: A Saga of the Year...\" by \"l. ron hubbard\"\n",
      "[1.095] \"Sarajevo Daily: A City and Its Newspa...\" by \"tom gjelten\"\n",
      "[1.094] \"My Century: A Novel\" by \"gunter grass\"\n",
      "[1.082] \"Fevre Dream\" by \"george r.r. martin\"\n",
      "[1.079] \"Tuf Voyaging\" by \"george r. r. martin\"\n",
      "[1.075] \"The Extended Phenotype: The Long Reac...\" by \"richard dawkins\"\n",
      "[1.074] \"Joker's Wild (Wild Cards, Vol 3)\" by \"george r.r. martin\"\n",
      "[1.071] \"Down and Dirty (Wild Cards, No 5)\" by \"george r.r. martin\"\n",
      "[1.067] \"The Green Lifestyle Handbook: 1001 Wa...\" by \"jeremy rifkin\"\n",
      "[1.066] \"The Danzig Trilogy: The Tin Drum, Cat...\" by \"gunter grass\"\n",
      "[1.065] \"Der entzauberte Regenbogen. Wissensch...\" by \"richard dawkins\"\n",
      "[1.065] \"Wild Cards (Volume 1)\" by \"george r.r. martin\"\n",
      "[1.064] \"Blood of the Fold (Sword of Truth, Bo...\" by \"terry goodkind\"\n"
     ]
    }
   ],
   "source": [
    "context_books = [\"0192177737\", \"0393316823\", \"0553381695\"]\n",
    "scored_books = recommend(context_books, same_book_isbn_map, isbn_to_proximal_isbns, use_positional_bias=True)\n",
    "display_recommendations(scored_books, context_books, book_to_author, book_to_title, best_n_only=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The books that the recommendations were based on:\n",
      "\"Eugenie Grandet\" by \"honore de balzac\"\n",
      "\"Crime &amp; Punishment\" by \"fyodor m. dostoevsky\"\n",
      "\"Red and the Black\" by \"stendhal\"\n",
      "\"The Sorrows of Young Werther (Modern ...\" by \"goethe\"\n",
      "\n",
      "The recommended books:\n",
      "[1.155] \"The Return of the King (The Lord of t...\" by \"j. r. r. tolkien\"\n",
      "[1.082] \"Animal Liberation\" by \"peter singer\"\n",
      "[1.076] \"The Pleasure of My Company: A Novel\" by \"steve martin\"\n",
      "[1.071] \"About the Author : A Novel\" by \"john colapinto\"\n",
      "[1.065] \"Cascades - \\Fahrenheit 451\\\" (Collins...\" by \"ray bradbury\"\n",
      "[1.055] \"Lonely Planet Spain (Serial)\" by \"john noble\"\n",
      "[1.054] \"Routledge Philosophy GuideBook to Pla...\" by \"nickolas pappas\"\n",
      "[1.052] \"Pere Goriot (Oxford World's Classics ...\" by \"honore de balzac\"\n",
      "[1.051] \"The Symposium (Penguin Classics)\" by \"plato\"\n",
      "[1.046] \"Great Dialogues of Plato (Signet Clas...\" by \"plato\"\n",
      "[1.045] \"The Red and the Black\" by \"stendhal\"\n",
      "[1.044] \"Scenes from a Courtesan's Life\" by \"honore de balzac\"\n",
      "[1.042] \"Le Rouge Et Le Noir (Textes En Franca...\" by \"stendhal\"\n",
      "[1.041] \"Symposium (Oxford World's Classics)\" by \"plato\"\n",
      "[1.038] \"Crimen y Castigo / Crime and Punishment\" by \"fyodor m. dostoevsky\"\n",
      "[1.036] \"Lonely Planet Provence &amp; the Cote...\" by \"nicola williams\"\n",
      "[1.034] \"The Underpants : A Play by Carl Stern...\" by \"steve martin\"\n",
      "[1.033] \"Lonely Planet Italy (Lonely Planet It...\" by \"helen gillman\"\n",
      "[1.032] \"LA Metamorfosis (Colecci?on Literaria...\" by \"franz kafka\"\n",
      "[1.032] \"TrÃ³pico de CÃ¡ncer\" by \"henry miller\"\n"
     ]
    }
   ],
   "source": [
    "context_books = [\"2070360318\", \"1566194334\", \"0451517938\", \"0679643087\"]\n",
    "scored_books = recommend(context_books, same_book_isbn_map, isbn_to_proximal_isbns, use_positional_bias=True)\n",
    "display_recommendations(scored_books, context_books, book_to_author, book_to_title, best_n_only=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Code-Cleanup'></a>\n",
    "### Cleanup\n",
    "\n",
    "\n",
    "When we're done with the endpoint, we can just delete it, which will terminate any instances we deployed to not be charged a lot of money. Optionally, you may go to your AWS Console (in the SageMaker service) and delete the endpoint from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
